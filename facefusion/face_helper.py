from functools import lru_cache
from typing import Dict, List, Optional, Sequence, Tuple

import cv2
import numpy
from cv2.typing import Size

try:
    import torch  # type: ignore
except Exception:  # pragma: no cover - optional dependency
    torch = None  # type: ignore

try:
    from facefusion.gpu.compositor import get_composer  # type: ignore
except Exception:  # pragma: no cover - optional dependency
    get_composer = None  # type: ignore

try:
    from cv2 import ximgproc  # type: ignore[attr-defined]
    _HAS_XIMGPROC = True
except Exception:  # pragma: no cover - optional dependency
    ximgproc = None  # type: ignore
    _HAS_XIMGPROC = False

from facefusion.types import Anchors, Angle, BoundingBox, Distance, FaceDetectorModel, FaceLandmark5, FaceLandmark68, Mask, Matrix, Points, Scale, Score, Translation, VisionFrame, WarpTemplate, WarpTemplateSet
from facefusion import state_manager

# Detect CUDA support in OpenCV if available
def _has_cv2_cuda() -> bool:
    try:
        return hasattr(cv2, 'cuda') and cv2.cuda.getCudaEnabledDeviceCount() > 0
    except Exception:
        return False

WARP_TEMPLATE_SET : WarpTemplateSet =\
{
	'arcface_112_v1': numpy.array(
	[
		[ 0.35473214, 0.45658929 ],
		[ 0.64526786, 0.45658929 ],
		[ 0.50000000, 0.61154464 ],
		[ 0.37913393, 0.77687500 ],
		[ 0.62086607, 0.77687500 ]
	]),
	'arcface_112_v2': numpy.array(
	[
		[ 0.34191607, 0.46157411 ],
		[ 0.65653393, 0.45983393 ],
		[ 0.50022500, 0.64050536 ],
		[ 0.37097589, 0.82469196 ],
		[ 0.63151696, 0.82325089 ]
	]),
	'arcface_128': numpy.array(
	[
		[ 0.36167656, 0.40387734 ],
		[ 0.63696719, 0.40235469 ],
		[ 0.50019687, 0.56044219 ],
		[ 0.38710391, 0.72160547 ],
		[ 0.61507734, 0.72034453 ]
	]),
	'dfl_whole_face': numpy.array(
	[
		[ 0.35342266, 0.39285716 ],
		[ 0.62797622, 0.39285716 ],
		[ 0.48660713, 0.54017860 ],
		[ 0.38839287, 0.68750011 ],
		[ 0.59821427, 0.68750011 ]
	]),
	'ffhq_512': numpy.array(
	[
		[ 0.37691676, 0.46864664 ],
		[ 0.62285697, 0.46912813 ],
		[ 0.50123859, 0.61331904 ],
		[ 0.39308822, 0.72541100 ],
		[ 0.61150205, 0.72490465 ]
	]),
	'mtcnn_512': numpy.array(
	[
		[ 0.36562865, 0.46733799 ],
		[ 0.63305391, 0.46585885 ],
		[ 0.50019127, 0.61942959 ],
		[ 0.39032951, 0.77598822 ],
		[ 0.61178945, 0.77476328 ]
	]),
	'styleganex_384': numpy.array(
	[
		[ 0.42353745, 0.52289879 ],
		[ 0.57725008, 0.52319972 ],
		[ 0.50123859, 0.61331904 ],
		[ 0.43364461, 0.68337652 ],
		[ 0.57015325, 0.68306005 ]
	])
}


class _OneEuroScalarFilter:
	def __init__(self, fps: float, min_cutoff: float = 1.0, beta: float = 0.03, dcutoff: float = 1.0) -> None:
		self._te = 1.0 / max(1e-3, fps)
		self._min_cutoff = float(min_cutoff)
		self._beta = float(beta)
		self._dcutoff = float(dcutoff)
		self._x_prev: Optional[float] = None
		self._dx_prev: float = 0.0

	def _alpha(self, cutoff: float) -> float:
		tau = 1.0 / (2.0 * numpy.pi * cutoff)
		return 1.0 / (1.0 + tau / self._te)

	def reset(self, value: float) -> None:
		self._x_prev = value
		self._dx_prev = 0.0

	def filter(self, value: float) -> float:
		if self._x_prev is None:
			self.reset(value)
			return value
		dx = (value - self._x_prev) / self._te
		alpha_d = self._alpha(self._dcutoff)
		self._dx_prev = alpha_d * dx + (1.0 - alpha_d) * self._dx_prev
		cutoff = self._min_cutoff + self._beta * abs(self._dx_prev)
		alpha = self._alpha(cutoff)
		filtered = alpha * value + (1.0 - alpha) * self._x_prev
		self._x_prev = filtered
		return filtered


class _AffineSmoother:
	def __init__(self, fps: float) -> None:
		self._filters = [_OneEuroScalarFilter(fps=fps) for _ in range(6)]
		self._initialized = False

	def apply(self, matrix: Matrix) -> Matrix:
		flat = numpy.asarray(matrix, dtype = numpy.float32).reshape(-1)
		if not self._initialized:
			for filt, value in zip(self._filters, flat):
				filt.reset(float(value))
			self._initialized = True
			return flat.reshape(matrix.shape)
		smoothed = numpy.empty_like(flat)
		for idx, value in enumerate(flat):
			smoothed[idx] = self._filters[idx].filter(float(value))
		return smoothed.reshape(matrix.shape)


_AFFINE_SMOOTHERS: Dict[str, _AffineSmoother] = {}


def _smooth_affine_matrix(track_token: Optional[str], matrix: Matrix) -> Matrix:
	if track_token is None:
		return matrix
	key = str(track_token)
	smoother = _AFFINE_SMOOTHERS.get(key)
	if smoother is None:
		fps = state_manager.get_item('output_video_fps')
		try:
			fps_val = float(fps) if fps else 30.0
		except Exception:
			fps_val = 30.0
		smoother = _AffineSmoother(fps_val)
		_AFFINE_SMOOTHERS[key] = smoother
	return smoother.apply(matrix)


def reset_affine_smoothers() -> None:
	_AFFINE_SMOOTHERS.clear()


def estimate_matrix_by_face_landmark_5(face_landmark_5 : FaceLandmark5, warp_template : WarpTemplate, crop_size : Size) -> Matrix:
	warp_template_norm = WARP_TEMPLATE_SET.get(warp_template) * crop_size
	affine_matrix = cv2.estimateAffinePartial2D(face_landmark_5, warp_template_norm, method = cv2.RANSAC, ransacReprojThreshold = 100)[0]
	return affine_matrix


def warp_face_by_face_landmark_5(temp_vision_frame : VisionFrame, face_landmark_5 : FaceLandmark5, warp_template : WarpTemplate, crop_size : Size) -> Tuple[VisionFrame, Matrix]:
    affine_matrix = estimate_matrix_by_face_landmark_5(face_landmark_5, warp_template, crop_size)
    if _has_cv2_cuda():
        try:
            gpu_img = cv2.cuda_GpuMat()
            gpu_img.upload(temp_vision_frame)
            # INTER_AREA for downscale; replicate border to mimic CPU path
            crop_gpu = cv2.cuda.warpAffine(gpu_img, affine_matrix, crop_size, flags=cv2.INTER_AREA, borderMode=cv2.BORDER_REPLICATE)
            crop_vision_frame = crop_gpu.download()
            return crop_vision_frame, affine_matrix
        except Exception:
            pass
    crop_vision_frame = cv2.warpAffine(temp_vision_frame, affine_matrix, crop_size, borderMode = cv2.BORDER_REPLICATE, flags = cv2.INTER_AREA)
    return crop_vision_frame, affine_matrix


def warp_face_by_bounding_box(temp_vision_frame : VisionFrame, bounding_box : BoundingBox, crop_size : Size) -> Tuple[VisionFrame, Matrix]:
	source_points = numpy.array([ [ bounding_box[0], bounding_box[1] ], [bounding_box[2], bounding_box[1] ], [ bounding_box[0], bounding_box[3] ] ]).astype(numpy.float32)
	target_points = numpy.array([ [ 0, 0 ], [ crop_size[0], 0 ], [ 0, crop_size[1] ] ]).astype(numpy.float32)
	affine_matrix = cv2.getAffineTransform(source_points, target_points)
	if bounding_box[2] - bounding_box[0] > crop_size[0] or bounding_box[3] - bounding_box[1] > crop_size[1]:
		interpolation_method = cv2.INTER_AREA
	else:
		interpolation_method = cv2.INTER_LINEAR
	crop_vision_frame = cv2.warpAffine(temp_vision_frame, affine_matrix, crop_size, flags = interpolation_method)
	return crop_vision_frame, affine_matrix


def warp_face_by_translation(temp_vision_frame : VisionFrame, translation : Translation, scale : float, crop_size : Size) -> Tuple[VisionFrame, Matrix]:
	affine_matrix = numpy.array([ [ scale, 0, translation[0] ], [ 0, scale, translation[1] ] ])
	crop_vision_frame = cv2.warpAffine(temp_vision_frame, affine_matrix, crop_size)
	return crop_vision_frame, affine_matrix


def paste_back(temp_vision_frame : VisionFrame, crop_vision_frame : VisionFrame, crop_mask : Mask, affine_matrix : Matrix, track_token: Optional[object] = None) -> VisionFrame:
	track_key = str(track_token) if track_token is not None else None
	if track_key is not None:
		affine_matrix = _smooth_affine_matrix(track_key, affine_matrix)
	paste_bounding_box, paste_matrix = calculate_paste_area(temp_vision_frame, crop_vision_frame, affine_matrix)
	x1, y1, x2, y2 = paste_bounding_box
	paste_width = x2 - x1
	paste_height = y2 - y1

	crop_mask = _refine_mask_with_guided_filter(crop_vision_frame, crop_mask)
	sdf_map = _compute_signed_distance(crop_mask)

	if paste_width <= 0 or paste_height <= 0:
		return temp_vision_frame

	inverse_mask = cv2.warpAffine(crop_mask, paste_matrix, (paste_width, paste_height)).clip(0, 1).astype(numpy.float32)
	if not numpy.any(inverse_mask):
		return temp_vision_frame

	gpu_result = _paste_back_cuda(temp_vision_frame, crop_vision_frame, inverse_mask, paste_matrix, paste_bounding_box, track_key, sdf_map)
	if gpu_result is not None:
		return gpu_result

	if _has_cv2_cuda():
		try:
			# Warp on GPU, blend on CPU for simplicity and correctness
			gpu_mask = cv2.cuda_GpuMat()
			gpu_mask.upload(crop_mask.astype(numpy.float32))
			inv_mask_gpu = cv2.cuda.warpAffine(gpu_mask, paste_matrix, (paste_width, paste_height))
			mask_roi = inv_mask_gpu.download().clip(0, 1)
			mask_roi = numpy.expand_dims(mask_roi, axis = -1)

			gpu_crop = cv2.cuda_GpuMat()
			gpu_crop.upload(crop_vision_frame)
			inv_frame_gpu = cv2.cuda.warpAffine(gpu_crop, paste_matrix, (paste_width, paste_height), borderMode = cv2.BORDER_REPLICATE)
			inverse_vision_frame = inv_frame_gpu.download()

			temp_vision_frame = temp_vision_frame.copy()
			paste_vision_frame = temp_vision_frame[y1:y2, x1:x2]
			paste_vision_frame = paste_vision_frame * (1 - mask_roi) + inverse_vision_frame * mask_roi
			temp_vision_frame[y1:y2, x1:x2] = paste_vision_frame.astype(temp_vision_frame.dtype)
			return temp_vision_frame
		except Exception:
			pass

	inverse_mask_expanded = numpy.expand_dims(inverse_mask, axis = -1)
	inverse_vision_frame = cv2.warpAffine(crop_vision_frame, paste_matrix, (paste_width, paste_height), borderMode = cv2.BORDER_REPLICATE)
	temp_vision_frame = temp_vision_frame.copy()
	paste_vision_frame = temp_vision_frame[y1:y2, x1:x2]
	# Convert to float32 for stable blending
	paste_f32 = paste_vision_frame.astype(numpy.float32)
	inv_frame_f32 = inverse_vision_frame.astype(numpy.float32)
	# Expand mask to 3 channels via OpenCV
	mask3 = cv2.merge([ inverse_mask_expanded[:, :, 0], inverse_mask_expanded[:, :, 0], inverse_mask_expanded[:, :, 0] ])
	one_minus = 1.0 - mask3
	part_a = cv2.multiply(paste_f32, one_minus)
	part_b = cv2.multiply(inv_frame_f32, mask3)
	blend = cv2.add(part_a, part_b)
	temp_vision_frame[y1:y2, x1:x2] = blend.astype(temp_vision_frame.dtype)
	return temp_vision_frame


_GPU_WARP_AVAILABLE: Optional[bool] = None


def _should_use_cuda_warp(area: int) -> bool:
	global _GPU_WARP_AVAILABLE
	if torch is None or not torch.cuda.is_available():
		return False
	if _GPU_WARP_AVAILABLE is False:
		return False
	if area < 65_536:  # Skip very small regions to avoid kernel launch overhead
		return False
	try:
		from facefusion import state_manager
		providers = state_manager.get_item('execution_providers') or []
		if not any(str(provider).lower() in ('cuda', 'tensorrt') for provider in providers):
			return False
	except Exception:
		pass
	return True


def _paste_back_cuda(temp_frame: VisionFrame, crop_frame: VisionFrame, roi_mask: Mask, paste_matrix: Matrix, paste_box: BoundingBox, track_token: Optional[str], sdf_map: Optional[Mask]) -> Optional[VisionFrame]:
	global _GPU_WARP_AVAILABLE
	if torch is None or get_composer is None:
		return None
	x1, y1, x2, y2 = map(int, paste_box)
	width = x2 - x1
	height = y2 - y1
	area = width * height
	if width <= 0 or height <= 0 or not _should_use_cuda_warp(area):
		return None
	device = torch.device('cuda')
	try:
		bg_roi = temp_frame[y1:y2, x1:x2]
		if bg_roi.shape[0] != height or bg_roi.shape[1] != width:
			return None

		composer = get_composer(device, height, width)
		crop_contig = numpy.ascontiguousarray(crop_frame)
		mask_contig = numpy.ascontiguousarray(roi_mask)
		bg_contig = numpy.ascontiguousarray(bg_roi)
		src_tensor = torch.from_numpy(crop_contig).to(device, non_blocking=True)
		mask_tensor = torch.from_numpy(mask_contig).to(device, non_blocking=True)
		bg_tensor = torch.from_numpy(bg_contig).to(device, non_blocking=True)
		affine_tensor = torch.from_numpy(paste_matrix.astype(numpy.float32)).to(device, non_blocking=True)
		extra_payload = { 'bg_reference': bg_contig }
		if sdf_map is not None:
			sdf_tensor = torch.from_numpy(numpy.ascontiguousarray(sdf_map)).to(device, non_blocking=True)
			extra_payload['sdf'] = sdf_tensor

		result = composer.compose(
			src_tensor,
			mask_tensor,
			bg_tensor,
			affine_tensor,
			track_token=track_token,
			extras=extra_payload
		)
		out_np = result.frame_bgr.contiguous().cpu().numpy()
		_GPU_WARP_AVAILABLE = True
		temp_out = temp_frame.copy()
		temp_out[y1:y2, x1:x2] = out_np
		return temp_out
	except Exception:
		_GPU_WARP_AVAILABLE = False
		return None


def _refine_mask_with_guided_filter(crop_frame: VisionFrame, mask: Mask) -> Mask:
	if mask.size == 0:
		return mask
	mask_f = mask.astype(numpy.float32)
	mask_f = numpy.clip(mask_f, 0.0, 1.0)
	if _HAS_XIMGPROC:
		try:
			guide = cv2.cvtColor(crop_frame, cv2.COLOR_BGR2GRAY)
			radius = 8
			eps = 1e-4
			refined = ximgproc.guidedFilter(guide, mask_f, radius, eps)
			return numpy.clip(refined, 0.0, 1.0)
		except Exception:
			pass
	# lightweight fallback: gentle gaussian smooth
	return cv2.GaussianBlur(mask_f, (0, 0), 1.2)


def _compute_signed_distance(mask: Mask) -> Mask:
	if mask.size == 0:
		return numpy.zeros_like(mask, dtype = numpy.float32)
	mask_binary = (mask >= 0.5).astype(numpy.uint8)
	if not mask_binary.any():
		return numpy.zeros_like(mask, dtype = numpy.float32)
	inside = cv2.distanceTransform(mask_binary, cv2.DIST_L2, 3)
	out = cv2.distanceTransform(1 - mask_binary, cv2.DIST_L2, 3)
	return (inside - out).astype(numpy.float32)


def calculate_paste_area(temp_vision_frame : VisionFrame, crop_vision_frame : VisionFrame, affine_matrix : Matrix) -> Tuple[BoundingBox, Matrix]:
	temp_height, temp_width = temp_vision_frame.shape[:2]
	crop_height, crop_width = crop_vision_frame.shape[:2]
	inverse_matrix = cv2.invertAffineTransform(affine_matrix)
	crop_points = numpy.array([ [ 0, 0 ], [ crop_width, 0 ], [ crop_width, crop_height ], [ 0, crop_height ] ])
	paste_region_points = transform_points(crop_points, inverse_matrix)
	paste_region_point_min = numpy.floor(paste_region_points.min(axis = 0)).astype(int)
	paste_region_point_max = numpy.ceil(paste_region_points.max(axis = 0)).astype(int)
	x1, y1 = numpy.clip(paste_region_point_min, 0, [ temp_width, temp_height ])
	x2, y2 = numpy.clip(paste_region_point_max, 0, [ temp_width, temp_height ])
	paste_bounding_box = numpy.array([ x1, y1, x2, y2 ])
	paste_matrix = inverse_matrix.copy()
	paste_matrix[0, 2] -= x1
	paste_matrix[1, 2] -= y1
	return paste_bounding_box, paste_matrix


@lru_cache()
def create_static_anchors(feature_stride : int, anchor_total : int, stride_height : int, stride_width : int) -> Anchors:
	x, y = numpy.mgrid[:stride_width, :stride_height]
	anchors = numpy.stack((y, x), axis = -1)
	anchors = (anchors * feature_stride).reshape((-1, 2))
	anchors = numpy.stack([ anchors ] * anchor_total, axis = 1).reshape((-1, 2))
	return anchors


def create_rotation_matrix_and_size(angle : Angle, size : Size) -> Tuple[Matrix, Size]:
	rotation_matrix = cv2.getRotationMatrix2D((size[0] / 2, size[1] / 2), angle, 1)
	rotation_size = numpy.dot(numpy.abs(rotation_matrix[:, :2]), size)
	rotation_matrix[:, -1] += (rotation_size - size) * 0.5 #type:ignore[misc]
	rotation_size = int(rotation_size[0]), int(rotation_size[1])
	return rotation_matrix, rotation_size


def create_bounding_box(face_landmark_68 : FaceLandmark68) -> BoundingBox:
	x1, y1 = numpy.min(face_landmark_68, axis = 0)
	x2, y2 = numpy.max(face_landmark_68, axis = 0)
	bounding_box = normalize_bounding_box(numpy.array([ x1, y1, x2, y2 ]))
	return bounding_box


def normalize_bounding_box(bounding_box : BoundingBox) -> BoundingBox:
	x1, y1, x2, y2 = bounding_box
	x1, x2 = sorted([ x1, x2 ])
	y1, y2 = sorted([ y1, y2 ])
	return numpy.array([ x1, y1, x2, y2 ])


def transform_points(points : Points, matrix : Matrix) -> Points:
	points = points.reshape(-1, 1, 2)
	points = cv2.transform(points, matrix) #type:ignore[assignment]
	points = points.reshape(-1, 2)
	return points


def transform_bounding_box(bounding_box : BoundingBox, matrix : Matrix) -> BoundingBox:
	points = numpy.array(
	[
		[ bounding_box[0], bounding_box[1] ],
		[ bounding_box[2], bounding_box[1] ],
		[ bounding_box[2], bounding_box[3] ],
		[ bounding_box[0], bounding_box[3] ]
	])
	points = transform_points(points, matrix)
	x1, y1 = numpy.min(points, axis = 0)
	x2, y2 = numpy.max(points, axis = 0)
	return normalize_bounding_box(numpy.array([ x1, y1, x2, y2 ]))


def distance_to_bounding_box(points : Points, distance : Distance) -> BoundingBox:
	x1 = points[:, 0] - distance[:, 0]
	y1 = points[:, 1] - distance[:, 1]
	x2 = points[:, 0] + distance[:, 2]
	y2 = points[:, 1] + distance[:, 3]
	bounding_box = numpy.column_stack([ x1, y1, x2, y2 ])
	return bounding_box


def distance_to_face_landmark_5(points : Points, distance : Distance) -> FaceLandmark5:
	x = points[:, 0::2] + distance[:, 0::2]
	y = points[:, 1::2] + distance[:, 1::2]
	face_landmark_5 = numpy.stack((x, y), axis = -1)
	return face_landmark_5


def scale_face_landmark_5(face_landmark_5 : FaceLandmark5, scale : Scale) -> FaceLandmark5:
	face_landmark_5_scale = face_landmark_5 - face_landmark_5[2]
	face_landmark_5_scale *= scale
	face_landmark_5_scale += face_landmark_5[2]
	return face_landmark_5_scale


def convert_to_face_landmark_5(face_landmark_68 : FaceLandmark68) -> FaceLandmark5:
	face_landmark_5 = numpy.array(
	[
		numpy.mean(face_landmark_68[36:42], axis = 0),
		numpy.mean(face_landmark_68[42:48], axis = 0),
		face_landmark_68[30],
		face_landmark_68[48],
		face_landmark_68[54]
	])
	return face_landmark_5


def estimate_face_angle(face_landmark_68 : FaceLandmark68) -> Angle:
	x1, y1 = face_landmark_68[0]
	x2, y2 = face_landmark_68[16]
	theta = numpy.arctan2(y2 - y1, x2 - x1)
	theta = numpy.degrees(theta) % 360
	angles = numpy.linspace(0, 360, 5)
	index = numpy.argmin(numpy.abs(angles - theta))
	face_angle = int(angles[index] % 360)
	return face_angle


def apply_nms(bounding_boxes : List[BoundingBox], scores : List[Score], score_threshold : float, nms_threshold : float) -> Sequence[int]:
	bounding_boxes_norm = [ (x1, y1, x2 - x1, y2 - y1) for (x1, y1, x2, y2) in bounding_boxes ]
	keep_indices = cv2.dnn.NMSBoxes(bounding_boxes_norm, scores, score_threshold = score_threshold, nms_threshold = nms_threshold)
	return keep_indices


def get_nms_threshold(face_detector_model : FaceDetectorModel, face_detector_angles : List[Angle]) -> float:
	if face_detector_model == 'many':
		return 0.1
	if len(face_detector_angles) == 2:
		return 0.3
	if len(face_detector_angles) == 3:
		return 0.2
	if len(face_detector_angles) == 4:
		return 0.1
	return 0.4


def merge_matrix(temp_matrices : List[Matrix]) -> Matrix:
	matrix = numpy.vstack([temp_matrices[0], [0, 0, 1]])

	for temp_matrix in temp_matrices[1:]:
		temp_matrix = numpy.vstack([ temp_matrix, [ 0, 0, 1 ] ])
		matrix = numpy.dot(temp_matrix, matrix)

	return matrix[:2, :]
